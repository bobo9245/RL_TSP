{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# 데이터 로드 함수\n",
    "def load_data(filepath):\n",
    "    with open(filepath, mode='r', newline='') as file:\n",
    "        data = [list(map(float, row)) for row in csv.reader(file)]\n",
    "    tensor_data = torch.tensor(data, dtype=torch.float32)\n",
    "    return tensor_data\n",
    "\n",
    "# 경로 시각화 함수\n",
    "def plot_path(path, coordinates):\n",
    "    coordinates = coordinates.numpy()\n",
    "    path = np.array(path + [path[0]])\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.plot(coordinates[path, 0], coordinates[path, 1], 'o-')\n",
    "    \n",
    "    plt.xlabel('X coordinate')\n",
    "    plt.ylabel('Y coordinate')\n",
    "    plt.title('Optimized Path')\n",
    "    plt.show()\n",
    "\n",
    "# 거리 계산 함수\n",
    "def distance(city1, city2):\n",
    "    return np.linalg.norm(city1 - city2)\n",
    "\n",
    "# 비용 계산 함수\n",
    "def calculate_cost(path, coordinates):\n",
    "    return np.sum([distance(coordinates[path[i]], coordinates[path[i+1]]) for i in range(len(path)-1)])\n",
    "\n",
    "# 초기 Value Table 및 Policy 초기화 함수\n",
    "def initialize_value_policy(num_cities):\n",
    "    value_table = np.zeros((num_cities, num_cities))\n",
    "    policy = np.zeros(num_cities, dtype=int)\n",
    "    return value_table, policy\n",
    "\n",
    "# Value Table 및 Policy 업데이트 함수\n",
    "def update_value_policy(value_table, policy, path, coordinates):\n",
    "    num_cities = len(coordinates)\n",
    "    for i in range(num_cities):\n",
    "        current_city = path[i]\n",
    "        next_city = path[(i + 1) % num_cities]\n",
    "        cost = distance(coordinates[current_city], coordinates[next_city])\n",
    "        value_table[current_city][next_city] = cost\n",
    "        policy[current_city] = next_city\n",
    "    return value_table, policy\n",
    "\n",
    "# Nearest Neighbor 알고리즘을 사용한 초기 경로 생성 함수\n",
    "def nearest_neighbor(cities):\n",
    "    num_cities = len(cities)\n",
    "    unvisited_cities = set(range(1, num_cities))\n",
    "    current_city = 0\n",
    "    tour = [current_city]\n",
    "    while unvisited_cities:\n",
    "        nearest_city = min(unvisited_cities, key=lambda city: distance(cities[current_city], cities[city]))\n",
    "        tour.append(nearest_city)\n",
    "        unvisited_cities.remove(nearest_city)\n",
    "        current_city = nearest_city\n",
    "    tour.append(0)\n",
    "    return tour\n",
    "\n",
    "# 유전 알고리즘의 변이 연산 함수\n",
    "def mutate(path, mutation_rate):\n",
    "    new_path = path[:]\n",
    "    num_cities = len(path)\n",
    "    for _ in range(int((num_cities - 2) * mutation_rate)):\n",
    "        swap_idx1, swap_idx2 = random.sample(range(1, num_cities - 1), 2)\n",
    "        new_path[swap_idx1], new_path[swap_idx2] = new_path[swap_idx2], new_path[swap_idx1]\n",
    "    return new_path\n",
    "\n",
    "# 유전 알고리즘의 교차 연산 함수\n",
    "def crossover(parent1, parent2):\n",
    "    size = len(parent1)\n",
    "    start, end = sorted(random.sample(range(size), 2))\n",
    "    child = [None] * size\n",
    "    child[start:end] = parent1[start:end]\n",
    "    ptr = end\n",
    "    for city in parent2:\n",
    "        if city not in child:\n",
    "            if ptr >= size:\n",
    "                ptr = 0\n",
    "            child[ptr] = city\n",
    "            ptr += 1\n",
    "    return child\n",
    "\n",
    "# 유전 알고리즘 함수\n",
    "def genetic_algorithm(coordinates, max_iterations, num_expansions, mutation_rate):\n",
    "    initial_path = nearest_neighbor(coordinates)\n",
    "    best_path = initial_path\n",
    "    best_cost = calculate_cost(initial_path, coordinates)\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        for _ in range(num_expansions):\n",
    "            new_path = mutate(best_path, mutation_rate)\n",
    "            new_cost = calculate_cost(new_path, coordinates)\n",
    "            if new_cost < best_cost:\n",
    "                best_path = new_path\n",
    "                best_cost = new_cost\n",
    "\n",
    "    return best_cost, best_path\n",
    "\n",
    "# Value Iteration 함수\n",
    "def value_iteration(distance_matrix, gamma=0.999, theta=1e-7):\n",
    "    num_cities = len(distance_matrix)\n",
    "    V = np.zeros(num_cities)\n",
    "    policy = np.zeros(num_cities, dtype=int)\n",
    "\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for state in range(num_cities):\n",
    "            v = V[state]\n",
    "            next_values = [distance_matrix[state][next_state] + gamma * V[next_state] for next_state in range(num_cities) if next_state != state]\n",
    "            min_value = min(next_values)\n",
    "            V[state] = min_value\n",
    "            policy[state] = np.argmin([distance_matrix[state][next_state] + gamma * V[next_state] for next_state in range(num_cities) if next_state != state])\n",
    "            delta = max(delta, abs(v - V[state]))\n",
    "            print(delta, theta)\n",
    "        if delta < theta:\n",
    "            break\n",
    "\n",
    "    return V, policy\n",
    "\n",
    "# 데이터 로드\n",
    "coordinates = load_data('../2024_AI_TSP.csv')\n",
    "num_cities = len(coordinates)\n",
    "\n",
    "# 초기 Value Table 및 Policy 초기화\n",
    "value_table, policy = initialize_value_policy(num_cities)\n",
    "\n",
    "# 유전 알고리즘을 사용하여 초기 경로 생성\n",
    "best_cost, best_path = genetic_algorithm(coordinates, max_iterations=1000, num_expansions=5, mutation_rate=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 경로 기반으로 Value Table 및 Policy 업데이트\n",
    "value_table, policy = update_value_policy(value_table, policy, best_path, coordinates)\n",
    "\n",
    "# Value Iteration을 사용하여 Value Table 및 Policy 갱신\n",
    "distance_matrix = cdist(coordinates.numpy(), coordinates.numpy())\n",
    "value_table, policy = value_iteration(distance_matrix)\n",
    "# 결과 출력 및 경로 시각화\n",
    "print(\"Value Table:\\n\", value_table)\n",
    "print(\"Policy:\\n\", policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_path_from_policy(policy):\n",
    "    num_cities = len(policy)\n",
    "    start_city = 0\n",
    "    path = [start_city]\n",
    "    current_city = start_city\n",
    "    visited = set(path)\n",
    "    \n",
    "    while len(visited) < num_cities:\n",
    "        next_city = policy[current_city]\n",
    "        if next_city in visited:\n",
    "            unvisited_cities = set(range(num_cities)) - visited\n",
    "            if unvisited_cities:\n",
    "                next_city = unvisited_cities.pop()\n",
    "            else:\n",
    "                break\n",
    "        path.append(next_city)\n",
    "        visited.add(next_city)\n",
    "        current_city = next_city\n",
    "    \n",
    "    return path\n",
    "path = generate_path_from_policy(policy)\n",
    "print('after update : ',calculate_cost(path, coordinates))\n",
    "plot_path(path, coordinates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
